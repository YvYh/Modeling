---
title: "Assignment 3"
author: "YU Hong"
date: "2018/11/9"
output: html_document
---

> Using the caret package, select at least five classifiers and apply them to the provided spambase data set.  

##Load train and test data
```{r}
library(caret)
data=read.csv("./spamlearn.txt",header = TRUE, sep = "\t",dec = ".")
test=read.csv("./spamtest.txt",header = TRUE, sep = "\t",dec = ".")
```

##Preparation of modeling  
Choose 2x5 cross-validation for each model training
```{r}
metric="Accuracy"
preProcess=c("center", "scale")
seed=1
control=trainControl(method="repeatedcv", number=2, repeats=5)
warnLevel=getOption("warn")
options(warn=-1)
```

##Train, predict and test models  
###1.Logistic Regression  
```{r}
set.seed(seed)
fit.glm <- train(Class~., data=data, method="glm", metric=metric, trControl=control)
pre.glm=predict(fit.glm,newdata = test)
rank.glm=confusionMatrix(table(test$Class, pre.glm))
rank.glm=rank.glm$overall["Accuracy"]
```
  
###2. knn
```{r}
set.seed(seed)
fit.knn <- train(Class~., data=data, method="knn", metric=metric, preProc=preProcess, trControl=control)
pre.knn=predict(fit.knn,newdata = test)
rank.knn=confusionMatrix(table(test$Class, pre.knn))
rank.knn=rank.knn$overall["Accuracy"]
```
  
###3. random forest
```{r}
set.seed(seed)
fit.rf <- train(Class~., data=data, method="rf", metric=metric, trControl=control)
pre.rf=predict(fit.rf, newdata = test)
rank.rf=confusionMatrix(table(test$Class,pre.knn))
rank.rf=rank.rf$overall["Accuracy"]
```
  
###4. Linear Discriminant Analysis
```{r}
set.seed(seed)
fit.lda <- train(Class~., data=data, method="lda", metric=metric, preProc=preProcess, trControl=control)
pre.lda=predict(fit.lda, newdata = test)
rank.lda=confusionMatrix(table(test$Class,pre.lda))
rank.lda=rank.lda$overall["Accuracy"]
```
  
###5. Stochastic Gradient Boosting (Generalized Boosted Modeling)
```{r}
set.seed(seed)
fit.gbm <- train(Class~., data=data, method="gbm", metric=metric, trControl=control, verbose=FALSE)
pre.gbm=predict(fit.gbm, newdata = test)
rank.gbm=confusionMatrix(table(test$Class,pre.gbm))
rank.gbm=rank.gbm$overall["Accuracy"]
```

  
## Compare the accuracy of the test results  
visualize the results as a dotplot  
```{r}
options(warn=warnLevel)
results=cbind(rank.gbm,rank.glm,rank.knn,rank.lda,rank.rf)
barplot(results[1,], ylab = "Accuracy", xpd = FALSE)
abline(h=max(results[1,]))
```
  
Here we can find out the **generalized boosted model** has the best performance (with an accuracy of `r rank.gbm`) in this dataset.

